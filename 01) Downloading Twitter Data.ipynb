{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import string\n",
    "import re #package that checks if a string matches a pattern eg being alphanumeric\n",
    "from nltk.corpus import stopwords #Package from natural language toolkit to get rid of stop words\n",
    "cd = 'C:\\\\Users\\\\Giada\\\\Documents\\\\GitHub\\\\Tweet-Sentiment-Predictor\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_tweets(stopwords, max_words, no_of_tweets, hashtag_phrase, output_dset):\n",
    "    consumer_token = \"O72v0C7nz9Ygfr5cyufGs42ZM\"\n",
    "    consumer_secret = \"951kq45KHoJdu91zo7WBvvx7Vp7oJQSi7Ed1bYZXqTupRyXW7j\"\n",
    "    access_token = \"1232356759009988609-9C5JCZ744UOgjsj86Gcwhq973VQ3YL\"\n",
    "    access_token_secret = \"rvm24BbxFdSmwwrlmHgxIWMs0zhbp1NvDEbIqci8012fK\"\n",
    "    auth = tweepy.OAuthHandler(consumer_token, consumer_secret)\n",
    "    auth.set_access_token(access_token, access_token_secret)\n",
    "    api = tweepy.API(auth)\n",
    "\n",
    "    #making a list 1 to max words for the column titles for the dataset\n",
    "    column_titles = list([\"word00\"])\n",
    "    for x in range(49):\n",
    "        column_titles.append(\"word\"+str(x+1).zfill(2))\n",
    "    df = pd.DataFrame(columns = column_titles)\n",
    "\n",
    "    #for each tweet matching our hashtags, write relevant info to the dataframe\n",
    "    for tweet in tweepy.Cursor(api.search, q=hashtag_phrase+' -filter:retweets', lang=\"en\", tweet_mode='extended').items(no_of_tweets):\n",
    "    \t#Splitting the chain of words up into a list of each individual word\n",
    "        #Usually called \"Tokenisation\"\n",
    "        words_temp_list = tweet.full_text.split()\n",
    "        \n",
    "        for x in range(len(words_temp_list)):\n",
    "            #Removing all words that start with an @ or # as these are usernames and often several combined words as a hashtag\n",
    "            if words_temp_list[x][:1] == '@':\n",
    "                words_temp_list[x] = ''\n",
    "            if words_temp_list[x][:1] == '#':\n",
    "                words_temp_list[x] = ''\n",
    "\n",
    "            #Removing non-alphabetical characters\n",
    "            words_temp_list[x] = replacement_values.sub('', words_temp_list[x])\n",
    "\n",
    "            #Removing weblinks which will start with http\n",
    "            if words_temp_list[x][:4] == 'http':\n",
    "                words_temp_list[x] = ''\n",
    "\n",
    "            #Making all words lowercase\n",
    "            words_temp_list[x] = words_temp_list[x].lower()\n",
    "\n",
    "            #Removing stop words\n",
    "            if words_temp_list[x] in stopwords:\n",
    "                words_temp_list[x] = ''\n",
    "\n",
    "        #Removing missing values left behind by strings of only non-alphabetical characters\n",
    "        words_temp_list = list(filter(None, words_temp_list)) \n",
    "\n",
    "        #Adding null values onto the end of list where there are no more words\n",
    "        for i in range(len(words_temp_list)+1,max_words + 1):\n",
    "        \twords_temp_list.append(np.nan)\n",
    "\n",
    "        #Adding the column names next to each word so that it can be added to the dataframe\n",
    "        words_list = [{\"word\"+str(i).zfill(2):words_temp_list[i] for i in range(max_words)}]\n",
    "        df = df.append(words_list,ignore_index=True)\n",
    "    output_dset = pd.concat([output_dset,df],ignore_index=True,sort=True)\n",
    "    return output_dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['below', 'down', 'when', 'more', 'haven', 'shes', 'very', 'only', 'shouldve', 'who', 'have', 'out', 'were', 'or', 'been', 'from', 'had', 'nor', 'dont', 'itself', 'does', 'once', 'shouldnt', 'of', 'before', 'most', 'isn', 'couldnt', 'they', 'didn', 'mustn', 'wasnt', 'don', 'i', 'in', 'youll', 'which', 'shant', 'youve', 'if', 'why', 'needn', 'weren', 'wasn', 'hers', 'this', 'wouldn', 'their', 've', 'did', 'then', 'yourselves', 'theirs', 'that', 'than', 'them', 'm', 'off', 'a', 'over', 'hadn', 'herself', 'is', 'myself', 'through', 'he', 'where', 'each', 'some', 'will', 'there', 'll', 'arent', 'doesn', 'you', 'few', 's', 'all', 'him', 'with', 'by', 'too', 'no', 'y', 'to', 'himself', 'me', 'other', 'mustnt', 'youd', 'these', 'do', 'until', 'being', 'doing', 'o', 'ours', 'are', 'both', 'ma', 'won', 'how', 'against', 'those', 'themselves', 'thatll', 'wouldnt', 'while', 'because', 'but', 'ourselves', 'further', 'yourself', 'mightnt', 'an', 'having', 'isnt', 'whom', 'about', 'on', 'hadnt', 'havent', 'be', 'doesnt', 'our', 'has', 'as', 'it', 'same', 'couldn', 'such', 'after', 're', 'under', 'can', 'up', 'now', 'her', 'should', 'own', 'shouldn', 'ain', 'the', 'here', 'wont', 'my', 'hasnt', 'youre', 'any', 'not', 'didnt', 'just', 'its', 'd', 'werent', 'into', 'neednt', 't', 'yours', 'was', 'during', 'mightn', 'above', 'for', 'its', 'his', 'am', 'between', 'we', 'your', 'what', 'at', 'she', 'and', 'so', 'hasn', 'again', 'aren', 'shan']\n"
     ]
    }
   ],
   "source": [
    "#Creating a list of stopwords-\n",
    "stopwords = list(set(stopwords.words('english')))\n",
    "#Removing all non-alphanumeric characters from stop words\n",
    "replacement_values = re.compile('[^a-zA-Z]')\n",
    "for x in range(len(stopwords)):\n",
    "    stopwords[x] = replacement_values.sub('', stopwords[x])\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading \"positive\" tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word00</th>\n",
       "      <th>word01</th>\n",
       "      <th>word02</th>\n",
       "      <th>word03</th>\n",
       "      <th>word04</th>\n",
       "      <th>word05</th>\n",
       "      <th>word06</th>\n",
       "      <th>word07</th>\n",
       "      <th>word08</th>\n",
       "      <th>word09</th>\n",
       "      <th>...</th>\n",
       "      <th>word40</th>\n",
       "      <th>word41</th>\n",
       "      <th>word42</th>\n",
       "      <th>word43</th>\n",
       "      <th>word44</th>\n",
       "      <th>word45</th>\n",
       "      <th>word46</th>\n",
       "      <th>word47</th>\n",
       "      <th>word48</th>\n",
       "      <th>word49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>guess</td>\n",
       "      <td>jus</td>\n",
       "      <td>b</td>\n",
       "      <td>accepted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>agreed</td>\n",
       "      <td>counterprotest</td>\n",
       "      <td>group</td>\n",
       "      <td>arrived</td>\n",
       "      <td>similarly</td>\n",
       "      <td>armed</td>\n",
       "      <td>menacing</td>\n",
       "      <td>five</td>\n",
       "      <td>ten</td>\n",
       "      <td>groups</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>happy</td>\n",
       "      <td>accepted</td>\n",
       "      <td>paper</td>\n",
       "      <td>however</td>\n",
       "      <td>conference</td>\n",
       "      <td>cancelled</td>\n",
       "      <td>ensure</td>\n",
       "      <td>safety</td>\n",
       "      <td>thanks</td>\n",
       "      <td>reviewers</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>accepted</td>\n",
       "      <td>choice</td>\n",
       "      <td>ending</td>\n",
       "      <td>pain</td>\n",
       "      <td>better</td>\n",
       "      <td>pain</td>\n",
       "      <td>cant</td>\n",
       "      <td>give</td>\n",
       "      <td>gift</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>praise</td>\n",
       "      <td>gladly</td>\n",
       "      <td>accepted</td>\n",
       "      <td>astrals</td>\n",
       "      <td>especially</td>\n",
       "      <td>councilors</td>\n",
       "      <td>wanted</td>\n",
       "      <td>think</td>\n",
       "      <td>gone</td>\n",
       "      <td>use</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     word00          word01    word02    word03      word04      word05  \\\n",
       "0     guess             jus         b  accepted         NaN         NaN   \n",
       "1    agreed  counterprotest     group   arrived   similarly       armed   \n",
       "2     happy        accepted     paper   however  conference   cancelled   \n",
       "3  accepted          choice    ending      pain      better        pain   \n",
       "4    praise          gladly  accepted   astrals  especially  councilors   \n",
       "\n",
       "     word06  word07  word08     word09  ... word40 word41 word42 word43  \\\n",
       "0       NaN     NaN     NaN        NaN  ...    NaN    NaN    NaN    NaN   \n",
       "1  menacing    five     ten     groups  ...    NaN    NaN    NaN    NaN   \n",
       "2    ensure  safety  thanks  reviewers  ...    NaN    NaN    NaN    NaN   \n",
       "3      cant    give    gift        NaN  ...    NaN    NaN    NaN    NaN   \n",
       "4    wanted   think    gone        use  ...    NaN    NaN    NaN    NaN   \n",
       "\n",
       "  word44 word45 word46 word47 word48 word49  \n",
       "0    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "1    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "2    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "3    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "4    NaN    NaN    NaN    NaN    NaN    NaN  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words = 50\n",
    "no_of_tweets = 50 \n",
    "\n",
    "df_accumulated = pd.read_csv('tweets_positive.csv', low_memory=False)\n",
    "\n",
    "#Reading a long list of \"positive\" hashtags from a file\n",
    "with open('hash_tag_file_positive.txt','r') as file:\n",
    "    hashtag_phrase_list = file.read().splitlines()\n",
    "\n",
    "#Running the data download function for all words in the list\n",
    "for i in range(len(hashtag_phrase_list)):\n",
    "    hashtag_phrase = hashtag_phrase_list[i]\n",
    "    hashtag_phrase = \"'{}'\".format(hashtag_phrase)\n",
    "    df_accumulated = download_tweets(\n",
    "                        stopwords = stopwords, \n",
    "                        max_words = max_words,\n",
    "                        no_of_tweets = no_of_tweets,\n",
    "                        hashtag_phrase=hashtag_phrase,\n",
    "                        output_dset = df_accumulated\n",
    "                        )\n",
    "\n",
    "df_accumulated.drop_duplicates(keep='last', inplace=True)\n",
    "df_accumulated.to_csv('tweets_positive.csv',index=False)\n",
    "df_accumulated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading \"negative\" tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word00</th>\n",
       "      <th>word01</th>\n",
       "      <th>word02</th>\n",
       "      <th>word03</th>\n",
       "      <th>word04</th>\n",
       "      <th>word05</th>\n",
       "      <th>word06</th>\n",
       "      <th>word07</th>\n",
       "      <th>word08</th>\n",
       "      <th>word09</th>\n",
       "      <th>...</th>\n",
       "      <th>word40</th>\n",
       "      <th>word41</th>\n",
       "      <th>word42</th>\n",
       "      <th>word43</th>\n",
       "      <th>word44</th>\n",
       "      <th>word45</th>\n",
       "      <th>word46</th>\n",
       "      <th>word47</th>\n",
       "      <th>word48</th>\n",
       "      <th>word49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>funny</td>\n",
       "      <td>agency</td>\n",
       "      <td>even</td>\n",
       "      <td>buy</td>\n",
       "      <td>support</td>\n",
       "      <td>itsm</td>\n",
       "      <td>toolwe</td>\n",
       "      <td>figure</td>\n",
       "      <td>lol</td>\n",
       "      <td>fact</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hear</td>\n",
       "      <td>think</td>\n",
       "      <td>goes</td>\n",
       "      <td>show</td>\n",
       "      <td>hes</td>\n",
       "      <td>currently</td>\n",
       "      <td>popular</td>\n",
       "      <td>meaning</td>\n",
       "      <td>assumption</td>\n",
       "      <td>clout</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google</td>\n",
       "      <td>q</td>\n",
       "      <td>earnings</td>\n",
       "      <td>offer</td>\n",
       "      <td>hope</td>\n",
       "      <td>ad</td>\n",
       "      <td>slump</td>\n",
       "      <td>bad</td>\n",
       "      <td>expect</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>feel</td>\n",
       "      <td>sorry</td>\n",
       "      <td>people</td>\n",
       "      <td>bad</td>\n",
       "      <td>sinus</td>\n",
       "      <td>act</td>\n",
       "      <td>ass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>live</td>\n",
       "      <td>video</td>\n",
       "      <td>ike</td>\n",
       "      <td>great</td>\n",
       "      <td>fun</td>\n",
       "      <td>people</td>\n",
       "      <td>missed</td>\n",
       "      <td>extremely</td>\n",
       "      <td>interesting</td>\n",
       "      <td>conversation</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   word00  word01    word02 word03   word04     word05   word06     word07  \\\n",
       "0   funny  agency      even    buy  support       itsm   toolwe     figure   \n",
       "1    hear   think      goes   show      hes  currently  popular    meaning   \n",
       "2  google       q  earnings  offer     hope         ad    slump        bad   \n",
       "3    feel   sorry    people    bad    sinus        act      ass        NaN   \n",
       "4    live   video       ike  great      fun     people   missed  extremely   \n",
       "\n",
       "        word08        word09  ... word40 word41 word42 word43 word44 word45  \\\n",
       "0          lol          fact  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1   assumption         clout  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "2       expect           NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3          NaN           NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "4  interesting  conversation  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "  word46 word47 word48 word49  \n",
       "0    NaN    NaN    NaN    NaN  \n",
       "1    NaN    NaN    NaN    NaN  \n",
       "2    NaN    NaN    NaN    NaN  \n",
       "3    NaN    NaN    NaN    NaN  \n",
       "4    NaN    NaN    NaN    NaN  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words = 50\n",
    "no_of_tweets = 50\n",
    "\n",
    "df_accumulated = pd.read_csv('tweets_negative.csv',low_memory=False)\n",
    "\n",
    "#Reading a long list of \"positive\" hashtags from a file\n",
    "with open('hash_tag_file_negative.txt','r') as file:\n",
    "    hashtag_phrase_list = file.read().splitlines()\n",
    "\n",
    "#Running the data download function for all words in the list\n",
    "for i in range(len(hashtag_phrase_list)):\n",
    "    hashtag_phrase = hashtag_phrase_list[i]\n",
    "    hashtag_phrase = \"'{}'\".format(hashtag_phrase)\n",
    "    df_accumulated = download_tweets(\n",
    "                        stopwords = stopwords,\n",
    "                        max_words = max_words,\n",
    "                        no_of_tweets = no_of_tweets,\n",
    "                        hashtag_phrase=hashtag_phrase,\n",
    "                        output_dset = df_accumulated\n",
    "                        )\n",
    "\n",
    "df_accumulated.drop_duplicates(keep='last', inplace=True)\n",
    "df_accumulated.to_csv('tweets_negative.csv',index=False)\n",
    "df_accumulated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading \"neutral\" tweets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word00</th>\n",
       "      <th>word01</th>\n",
       "      <th>word02</th>\n",
       "      <th>word03</th>\n",
       "      <th>word04</th>\n",
       "      <th>word05</th>\n",
       "      <th>word06</th>\n",
       "      <th>word07</th>\n",
       "      <th>word08</th>\n",
       "      <th>word09</th>\n",
       "      <th>...</th>\n",
       "      <th>word40</th>\n",
       "      <th>word41</th>\n",
       "      <th>word42</th>\n",
       "      <th>word43</th>\n",
       "      <th>word44</th>\n",
       "      <th>word45</th>\n",
       "      <th>word46</th>\n",
       "      <th>word47</th>\n",
       "      <th>word48</th>\n",
       "      <th>word49</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>im</td>\n",
       "      <td>glad</td>\n",
       "      <td>see</td>\n",
       "      <td>modern</td>\n",
       "      <td>generation</td>\n",
       "      <td>experience</td>\n",
       "      <td>slave</td>\n",
       "      <td>trade</td>\n",
       "      <td>animal</td>\n",
       "      <td>crossing</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spend</td>\n",
       "      <td>whole</td>\n",
       "      <td>day</td>\n",
       "      <td>trying</td>\n",
       "      <td>fix</td>\n",
       "      <td>one</td>\n",
       "      <td>bug</td>\n",
       "      <td>still</td>\n",
       "      <td>done</td>\n",
       "      <td>send</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>think</td>\n",
       "      <td>theres</td>\n",
       "      <td>great</td>\n",
       "      <td>new</td>\n",
       "      <td>opportunity</td>\n",
       "      <td>local</td>\n",
       "      <td>growers</td>\n",
       "      <td>producers</td>\n",
       "      <td>also</td>\n",
       "      <td>one</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>got</td>\n",
       "      <td>hops</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>well</td>\n",
       "      <td>disappointing</td>\n",
       "      <td>fleming</td>\n",
       "      <td>presser</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  word00         word01   word02   word03       word04      word05   word06  \\\n",
       "0     im           glad      see   modern   generation  experience    slave   \n",
       "1  spend          whole      day   trying          fix         one      bug   \n",
       "2  think         theres    great      new  opportunity       local  growers   \n",
       "3    got           hops      NaN      NaN          NaN         NaN      NaN   \n",
       "4   well  disappointing  fleming  presser          NaN         NaN      NaN   \n",
       "\n",
       "      word07  word08    word09  ... word40 word41 word42 word43 word44 word45  \\\n",
       "0      trade  animal  crossing  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "1      still    done      send  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "2  producers    also       one  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "3        NaN     NaN       NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "4        NaN     NaN       NaN  ...    NaN    NaN    NaN    NaN    NaN    NaN   \n",
       "\n",
       "  word46 word47 word48 word49  \n",
       "0    NaN    NaN    NaN    NaN  \n",
       "1    NaN    NaN    NaN    NaN  \n",
       "2    NaN    NaN    NaN    NaN  \n",
       "3    NaN    NaN    NaN    NaN  \n",
       "4    NaN    NaN    NaN    NaN  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_words = 50\n",
    "no_of_tweets = 2000\n",
    "\n",
    "df_accumulated = pd.read_csv('tweets_neutral.csv',low_memory=False)\n",
    "\n",
    "df_accumulated = download_tweets(\n",
    "                        stopwords = stopwords,\n",
    "                        max_words = max_words,\n",
    "                        no_of_tweets = no_of_tweets,\n",
    "                        hashtag_phrase=\"\",\n",
    "                        output_dset = df_accumulated\n",
    "                        )\n",
    "\n",
    "df_accumulated.drop_duplicates(keep='last', inplace=True)\n",
    "df_accumulated.to_csv('tweets_neutral.csv',index=False)\n",
    "df_accumulated.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging a dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word00</th>\n",
       "      <th>word01</th>\n",
       "      <th>word02</th>\n",
       "      <th>word03</th>\n",
       "      <th>word04</th>\n",
       "      <th>word05</th>\n",
       "      <th>word06</th>\n",
       "      <th>word07</th>\n",
       "      <th>word08</th>\n",
       "      <th>word09</th>\n",
       "      <th>...</th>\n",
       "      <th>word41</th>\n",
       "      <th>word42</th>\n",
       "      <th>word43</th>\n",
       "      <th>word44</th>\n",
       "      <th>word45</th>\n",
       "      <th>word46</th>\n",
       "      <th>word47</th>\n",
       "      <th>word48</th>\n",
       "      <th>word49</th>\n",
       "      <th>SCORE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>agreed</td>\n",
       "      <td>counterprotest</td>\n",
       "      <td>group</td>\n",
       "      <td>arrived</td>\n",
       "      <td>similarly</td>\n",
       "      <td>armed</td>\n",
       "      <td>menacing</td>\n",
       "      <td>five</td>\n",
       "      <td>ten</td>\n",
       "      <td>groups</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>happy</td>\n",
       "      <td>accepted</td>\n",
       "      <td>paper</td>\n",
       "      <td>however</td>\n",
       "      <td>conference</td>\n",
       "      <td>cancelled</td>\n",
       "      <td>ensure</td>\n",
       "      <td>safety</td>\n",
       "      <td>thanks</td>\n",
       "      <td>reviewers</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>accepted</td>\n",
       "      <td>choice</td>\n",
       "      <td>ending</td>\n",
       "      <td>pain</td>\n",
       "      <td>better</td>\n",
       "      <td>pain</td>\n",
       "      <td>cant</td>\n",
       "      <td>give</td>\n",
       "      <td>gift</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>praise</td>\n",
       "      <td>gladly</td>\n",
       "      <td>accepted</td>\n",
       "      <td>astrals</td>\n",
       "      <td>especially</td>\n",
       "      <td>councilors</td>\n",
       "      <td>wanted</td>\n",
       "      <td>think</td>\n",
       "      <td>gone</td>\n",
       "      <td>use</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>could</td>\n",
       "      <td>accepted</td>\n",
       "      <td>grace</td>\n",
       "      <td>literally</td>\n",
       "      <td>option</td>\n",
       "      <td>funny</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     word00          word01    word02     word03      word04      word05  \\\n",
       "0    agreed  counterprotest     group    arrived   similarly       armed   \n",
       "1     happy        accepted     paper    however  conference   cancelled   \n",
       "2  accepted          choice    ending       pain      better        pain   \n",
       "3    praise          gladly  accepted    astrals  especially  councilors   \n",
       "4     could        accepted     grace  literally      option       funny   \n",
       "\n",
       "     word06  word07  word08     word09  ... word41 word42 word43 word44  \\\n",
       "0  menacing    five     ten     groups  ...    NaN    NaN    NaN    NaN   \n",
       "1    ensure  safety  thanks  reviewers  ...    NaN    NaN    NaN    NaN   \n",
       "2      cant    give    gift        NaN  ...    NaN    NaN    NaN    NaN   \n",
       "3    wanted   think    gone        use  ...    NaN    NaN    NaN    NaN   \n",
       "4       NaN     NaN     NaN        NaN  ...    NaN    NaN    NaN    NaN   \n",
       "\n",
       "  word45 word46 word47 word48 word49 SCORE  \n",
       "0    NaN    NaN    NaN    NaN    NaN     1  \n",
       "1    NaN    NaN    NaN    NaN    NaN     1  \n",
       "2    NaN    NaN    NaN    NaN    NaN     1  \n",
       "3    NaN    NaN    NaN    NaN    NaN     1  \n",
       "4    NaN    NaN    NaN    NaN    NaN     1  \n",
       "\n",
       "[5 rows x 51 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Function to load data and remove tweets with less than 5 words\n",
    "def Loading_Data(csv_file):\n",
    "    df = pd.read_csv(csv_file,low_memory=False)\n",
    "    df_copy = df.copy()\n",
    "    for i in range(len(df)):\n",
    "        if df.iloc[i,5] is np.nan:\n",
    "            df_copy = df_copy.drop([i], axis=0)\n",
    "    return df_copy\n",
    "\n",
    "\n",
    "\n",
    "positive_df = Loading_Data(csv_file ='tweets_positive.csv')\n",
    "negative_df = Loading_Data(csv_file ='tweets_negative.csv')\n",
    "neutral_df = Loading_Data(csv_file ='tweets_neutral.csv')\n",
    "\n",
    "#Setting a target score representing the sentiment of each tweet\n",
    "positive_df[\"SCORE\"] = 1\n",
    "negative_df[\"SCORE\"] = -1\n",
    "neutral_df[\"SCORE\"] = 0\n",
    "\n",
    "total_dset = positive_df.append(negative_df,ignore_index=True)\n",
    "total_dset = total_dset.append(neutral_df,ignore_index=True)\n",
    "\n",
    "total_dset.drop_duplicates(keep='last', inplace=True)\n",
    "\n",
    "total_dset.to_csv('Tweets_Combined.csv',index=False)\n",
    "\n",
    "total_dset.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
