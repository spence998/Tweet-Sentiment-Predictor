{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "import gensim\n",
    "import time\n",
    "import pickle\n",
    "cd = 'C:\\\\Users\\\\Giada\\\\Documents\\\\GitHub\\\\Tweet-Sentiment-Predictor\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loops each word through the list of categories and assigns the word the most similar category\n",
    "def category_chooser(word,categories,w2vmodel):\n",
    "    most_similar_category = len(categories)-1\n",
    "    #best similarity chosen as a minimum cosine similarity needed for another category to be chosen\n",
    "    best_similarity = 0.6\n",
    "    for i in range(len(categories)-1):\n",
    "        temp_similarity = w2vmodel.wv.similarity(word,categories[i])\n",
    "        if temp_similarity > best_similarity: \n",
    "            best_similarity = temp_similarity\n",
    "            most_similar_category = i\n",
    "    return most_similar_category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_predictions(dataset,pos_model,neg_model,positive_target,negative_target):\n",
    "    #Calculates the predictions \n",
    "    pos_probs = pos_model.predict_proba(dataset)[:,1]\n",
    "    neg_probs = neg_model.predict_proba(dataset)[:,1]\n",
    "    return pos_probs,neg_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treating the data into a format that can be scored"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pulling the stop words from nltk\n",
    "stopwords = list(set(stopwords.words('english')))\n",
    "replacement_values = re.compile('[^a-zA-Z]') #Removing all non-alphanumeric characters from stop words\n",
    "\n",
    "#Reading a long list of categories from the dataset catagory file\n",
    "with open('Dataset_Categories.txt','r') as file:\n",
    "    categories = file.read().splitlines()\n",
    "file.close()\n",
    "\n",
    "#Pulling the test dataset \n",
    "test_data = pd.read_csv(\"kaggle_train.csv\",index_col=\"textID\")\n",
    "test_target = list(test_data[\"sentiment\"])\n",
    "\n",
    "#unpickling the models\n",
    "with open('pos_model.sav', 'rb') as pickle_file:\n",
    "    pos_model = pickle.load(pickle_file)\n",
    "with open('neg_model.sav', 'rb') as pickle_file:\n",
    "    neg_model = pickle.load(pickle_file)\n",
    "\n",
    "dataset_final = pd.DataFrame(columns=categories,index=range(len(test_data)))\n",
    "w2vmodel = gensim.models.KeyedVectors.load('w2vmodel')\n",
    "\n",
    "for sentence in range(len(test_data)):\n",
    "    split_text = test_data[\"text\"][sentence].split()\n",
    "    for tweet_number in range(len(split_text)):\n",
    "        #Removing all words that start with an @ or # as these are usernames and often several combined words as a hashtag\n",
    "        if split_text[tweet_number][:1] == '@':\n",
    "            split_text[tweet_number] = ''\n",
    "        if split_text[tweet_number][:1] == '#':\n",
    "            split_text[tweet_number] = ''\n",
    "\n",
    "        #Removing non-alphabetical characters\n",
    "        split_text[tweet_number] = replacement_values.sub('', split_text[tweet_number])\n",
    "\n",
    "        #Removing weblinks which will start with http\n",
    "        if split_text[tweet_number][:4] == 'http':\n",
    "            split_text[tweet_number] = ''\n",
    "\n",
    "        #Making all words lowercase\n",
    "        split_text[tweet_number] = split_text[tweet_number].lower()\n",
    "\n",
    "        #Removing stop words\n",
    "        if split_text[tweet_number] in stopwords:\n",
    "            split_text[tweet_number] = ''\n",
    "\n",
    "    #Removing missing values left behind by strings of only non-alphabetical characters\n",
    "    split_text = list(filter(None, split_text))\n",
    "\n",
    "    #Setting all initial values to 0 in the final dset\n",
    "    dataset_final.iloc[sentence,:] = 0\n",
    "    #Loop through all of the words in the tweet\n",
    "    for word_number in range(len(split_text)):\n",
    "        word = split_text[word_number]\n",
    "        #If statement to check the words are in the model vocab\n",
    "        if word is not np.nan and word in w2vmodel.wv.vocab.keys():\n",
    "            category_number = category_chooser(word=word,categories=categories,w2vmodel=w2vmodel)\n",
    "            dataset_final.iloc[sentence,category_number] = dataset_final.iloc[sentence,category_number] + 1\n",
    "\n",
    "modelling_dset.to_csv('modelling_kaggle_dset_train.csv',index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scoring up the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_target = list(test_data[\"sentiment\"])\n",
    "\n",
    "#Positive target list\n",
    "test_target_pos = []\n",
    "for target in range(len(test_target)):\n",
    "    if test_target[target] == \"positive\":\n",
    "        test_target_pos.append(1)\n",
    "    else:\n",
    "        test_target_pos.append(0)\n",
    "\n",
    "#Negative target list\n",
    "test_target_neg = []\n",
    "for target in range(len(test_target)):\n",
    "    if test_target[target] == \"negative\":\n",
    "        test_target_neg.append(1)\n",
    "    else:\n",
    "        test_target_neg.append(0)\n",
    "        \n",
    "\n",
    "pos_probs,neg_probs = model_predictions(dataset=modelling_dset\n",
    "                        ,pos_model=pos_model\n",
    "                        ,neg_model=neg_model\n",
    "                        ,positive_target=test_target_pos\n",
    "                        ,negative_target=test_target_neg)\n",
    "\n",
    "test_data[\"pos_probs\"] = pos_probs\n",
    "test_data[\"neg_probs\"] = neg_probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cycling through negative and positive cut-offs to find the pair of cut-offs which produces the most accurate predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive cutoff 0.39\n",
      "Negative cutoff 0.5700000000000001\n",
      "Best accuracy 0.544708545557442\n"
     ]
    }
   ],
   "source": [
    "#Loop through the best cut-offs to find the most accurate cutoffs\n",
    "best_accuracy = 0\n",
    "for pos_cutoff_x in range(35):\n",
    "    pos_cutoff = 0.3 + 0.01*pos_cutoff_x\n",
    "    for neg_cutoff_x in range(35):\n",
    "        neg_cutoff = 0.3 + 0.01*neg_cutoff_x\n",
    "\n",
    "        test_data.loc[(test_data[\"pos_probs\"] > pos_cutoff) & (test_data[\"neg_probs\"] > neg_cutoff), \"OUTCOME\"] = \"BOTH\"\n",
    "        test_data.loc[(test_data[\"pos_probs\"] > pos_cutoff) & (test_data[\"neg_probs\"] < neg_cutoff), \"OUTCOME\"] = \"positive\"\n",
    "        test_data.loc[(test_data[\"pos_probs\"] < pos_cutoff) & (test_data[\"neg_probs\"] > neg_cutoff), \"OUTCOME\"] = \"negative\"\n",
    "        test_data.loc[(test_data[\"pos_probs\"] < pos_cutoff) & (test_data[\"neg_probs\"] < neg_cutoff), \"OUTCOME\"] = \"neutral\"\n",
    "\n",
    "        test_data.loc[(test_data[\"OUTCOME\"] == \"BOTH\") & (test_data[\"pos_probs\"] > test_data[\"neg_probs\"]), \"OUTCOME\"] = \"positive\"\n",
    "        test_data.loc[(test_data[\"OUTCOME\"] == \"BOTH\") & (test_data[\"pos_probs\"] < test_data[\"neg_probs\"]), \"OUTCOME\"] = \"negative\"\n",
    "\n",
    "        test_data.loc[test_data[\"OUTCOME\"] == test_data[\"sentiment\"], \"ACCURACY\"] = 1\n",
    "        test_data.loc[test_data[\"OUTCOME\"] != test_data[\"sentiment\"], \"ACCURACY\"] = 0\n",
    "\n",
    "        #Calculating the accuracy of the prediction\n",
    "        total_correct_predictions = test_data[\"ACCURACY\"].sum()\n",
    "        accuracy = total_correct_predictions/len(test_data)\n",
    "        if  best_accuracy < accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            P_CO = pos_cutoff\n",
    "            N_CO = neg_cutoff\n",
    "\n",
    "print(\"Positive cutoff \" + str(P_CO))\n",
    "print(\"Negative cutoff \" + str(N_CO))\n",
    "print(\"Best accuracy \" + str(best_accuracy))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
